{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a45403",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from ta.trend import WMAIndicator\n",
    "from ta.trend import SMAIndicator\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.volatility import AverageTrueRange\n",
    "from ta.volume import AccDistIndexIndicator\n",
    "from ta.utils import IndicatorMixin\n",
    "\n",
    "class AccDistOscillatorIndicator(IndicatorMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        high: pd.Series,\n",
    "        low: pd.Series,\n",
    "        closeY: pd.Series,\n",
    "        fillna: bool = False,\n",
    "    ):\n",
    "        \n",
    "        self._high = high\n",
    "        self._low = low\n",
    "        self._closeY = closeY\n",
    "        self._fillna = fillna\n",
    "        self._run()\n",
    "        \n",
    "    def _run(self):\n",
    "        ado = (self._high - self._closeY)/(self._high - self._low)\n",
    "        self._ado = ado\n",
    "        \n",
    "    def acc_dist_oscillator(self) -> pd.Series:\n",
    "        ado = self._check_fillna(self._ado, value=0)\n",
    "        return pd.Series(ado, name=\"ado\")\n",
    "\n",
    "def acc_dist_oscillator(high, low, closeY, fillna=False):\n",
    "    return AccDistOscillatorIndicator(high=high, low=low, closeY=closeY, fillna=fillna).acc_dist_oscillator()\n",
    "    \n",
    "def ticker_data_processing(ticker, time_period):\n",
    "    tick = yf.download(ticker, period=time_period)\n",
    "    tickerData = tick\n",
    "    #adjusting the Adj Close columns \n",
    "    tickerData = tickerData.drop(['Adj Close'], axis =1)\n",
    "    close = tickerData['Close']\n",
    "    tickerData['Today Close'] = close\n",
    "    tickerData['Close'] = tickerData['Close'].shift(-1)\n",
    "    tickerData = tickerData.rename(columns={\"Close\" : \"Tomorrow Close\"})\n",
    "    tickerData['Yesterday Close'] = tickerData['Today Close'].shift(+1)\n",
    "    tickerData = tickerData.dropna()\n",
    "    \n",
    "    #using TA library to calculate and add TA data to the data set\n",
    "    indicator_wma = WMAIndicator(close=tickerData[\"Today Close\"], window = 10)\n",
    "    tickerData['WMA'] = indicator_wma.wma()\n",
    "    \n",
    "    indicator_rsi = RSIIndicator(close=tickerData[\"Today Close\"], window = 10)\n",
    "    tickerData['RSI'] = indicator_rsi.rsi()\n",
    "    \n",
    "    indicator_atr = AverageTrueRange(high=tickerData[\"High\"], low=tickerData[\"Low\"], close=tickerData[\"Today Close\"], window = 10)\n",
    "    tickerData['ATR'] = indicator_atr.average_true_range()\n",
    "    \n",
    "    indicator_sma = SMAIndicator(close=tickerData[\"Today Close\"], window = 10)\n",
    "    tickerData['SMA'] = indicator_sma.sma_indicator()\n",
    "    \n",
    "    indicator_ado = AccDistOscillatorIndicator(high=tickerData[\"High\"], low=tickerData[\"Low\"], closeY=tickerData[\"Yesterday Close\"])\n",
    "    tickerData['ADO'] = indicator_ado.acc_dist_oscillator()\n",
    "    \n",
    "    tickerData = tickerData.drop(tickerData.index[:9])\n",
    "   \n",
    "    #print(tickerData) ##########################################################################\n",
    "    \n",
    "    #graphing the TA indicators\n",
    "    #fig, grph = plt.subplots(5, figsize =(20, 50))\n",
    "    #grph[0].plot(tickerData['WMA'])\n",
    "    #grph[1].plot(tickerData['RSI'])\n",
    "    #grph[2].plot(tickerData['ATR'])\n",
    "    #grph[3].plot(tickerData['SMA'])\n",
    "    #grph[4].plot(tickerData['ADO'])\n",
    "    \n",
    "    #drops N/A\n",
    "    tickerData = tickerData.dropna()\n",
    "    tickerData = tickerData.drop(['Volume', 'Open', 'High', 'Low', 'Today Close'], axis=1)\n",
    "    \n",
    "    #splitting the test and train data and dropping volume from both\n",
    "    train_set, test_set = train_test_split(tickerData, test_size=0.3, shuffle=False)\n",
    "    \n",
    "    #setting up the scaler\n",
    "    scale = ['WMA', 'RSI', 'ADO', 'ATR', 'SMA']\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    #seperate features and labels\n",
    "    train_set_features = train_set.drop([\"Tomorrow Close\"], axis=1) \n",
    "    train_set_labels = train_set['Tomorrow Close'].copy()\n",
    "    \n",
    "    test_set_features = test_set.drop(['Tomorrow Close'], axis=1)\n",
    "    test_set_labels = test_set['Tomorrow Close'].copy()\n",
    "    \n",
    "    #scaling the features\n",
    "    feature_transform = scaler.fit_transform(train_set_features[scale])\n",
    "    train_prepared = pd.DataFrame(columns=scale, data=feature_transform, index=train_set_features.index)\n",
    "    \n",
    "    feature_transform = scaler.transform(test_set_features[scale])\n",
    "    test_prepared = pd.DataFrame(columns=scale, data=feature_transform, index=test_set_features.index)\n",
    "    \n",
    "    \n",
    "    return train_prepared, train_set_labels, test_prepared, test_set_labels \n",
    "\n",
    "ticker_data_processing('F', '5y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b8bd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "def svr_linear(ticker, period):\n",
    "    train_prepared, train_set_labels, test_prepared, test_set_labels = ticker_data_processing(ticker, period)\n",
    "    plt.close()\n",
    "    svm_reg = SVR(kernel=\"linear\", epsilon= .5, C=34058.19149792883, max_iter=2500)\n",
    "    svm_reg.fit(train_prepared, train_set_labels)\n",
    "    \n",
    "    predictions = svm_reg.predict(test_prepared)\n",
    "    \n",
    "    scores = cross_val_score(svm_reg, train_prepared, train_set_labels, scoring=\"neg_mean_squared_error\", cv=5 )\n",
    "    \n",
    "    rmse = np.sqrt(-scores)\n",
    "    print(\"Scores:\", rmse)\n",
    "    print(\"Mean:\", rmse.mean())\n",
    "    print (\"Standared deviation:\", rmse.std())\n",
    "    print(\"MAPE: \", mean_absolute_percentage_error(test_set_labels, predictions))\n",
    "    \n",
    "    \n",
    "    test_prepared['Predicted Close'] = predictions.tolist()\n",
    "    test_prepared['Predicted Close'].plot(label=\"Predicted\", figsize=(24,12))\n",
    "    test_set_labels.plot(label=\"Close\")\n",
    "    plt.legend()\n",
    "    \n",
    "svr_linear('F', '15y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d119070d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "def svr_polynomial(ticker, period):\n",
    "    train_prepared, train_set_labels, test_prepared, test_set_labels = ticker_data_processing(ticker, period)\n",
    "    plt.close()\n",
    "    svm_reg = SVR(kernel= 'poly', epsilon= .5, C=2, degree=1, gamma=10, max_iter=2500)\n",
    "    svm_reg.fit(train_prepared, train_set_labels)\n",
    "    \n",
    "    predictions = svm_reg.predict(test_prepared)\n",
    "    \n",
    "    scores = cross_val_score(svm_reg, train_prepared, train_set_labels, scoring=\"neg_mean_squared_error\", cv=5 )\n",
    "    \n",
    "    rmse = np.sqrt(-scores)\n",
    "    print(\"Scores:\", rmse)\n",
    "    print(\"Mean:\", rmse.mean())\n",
    "    print (\"Standared deviation:\", rmse.std())\n",
    "    print(\"MAPE: \", mean_absolute_percentage_error(test_set_labels, predictions))\n",
    "    \n",
    "    \n",
    "    test_prepared['Predicted Close'] = predictions.tolist()\n",
    "    test_prepared['Predicted Close'].plot(label=\"Predicted\", figsize=(24,12))\n",
    "    test_set_labels.plot(label=\"Close\")\n",
    "    plt.legend()\n",
    "    \n",
    "svr_polynomial('F', '15y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e50df9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def svr_rbf(ticker, period):\n",
    "    train_prepared, train_set_labels, test_prepared, test_set_labels = ticker_data_processing(ticker, period)\n",
    "    plt.close()\n",
    "    svm_reg = SVR(kernel= 'rbf', epsilon= .5, C=2.0, gamma=0.10292942782029627, max_iter=2500)\n",
    "    svm_reg.fit(train_prepared, train_set_labels)\n",
    "    \n",
    "    predictions = svm_reg.predict(test_prepared)\n",
    "    \n",
    "    scores = cross_val_score(svm_reg, train_prepared, train_set_labels, scoring=\"neg_mean_squared_error\", cv=5 )\n",
    "    \n",
    "    rmse = np.sqrt(-scores)\n",
    "    print(\"Scores:\", rmse)\n",
    "    print(\"Mean:\", rmse.mean())\n",
    "    print (\"Standared deviation:\", rmse.std())\n",
    "    print(\"MAPE: \", mean_absolute_percentage_error(test_set_labels, predictions))\n",
    "    \n",
    "    \n",
    "    test_prepared['Predicted Close'] = predictions.tolist()\n",
    "    test_prepared['Predicted Close'].plot(label=\"Predicted\", figsize=(24,12))\n",
    "    test_set_labels.plot(label=\"Close\")\n",
    "    plt.legend()\n",
    "    \n",
    "svr_rbf('F', '15y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f6ac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "def randomWalk(ticker, period):\n",
    "    plt.close()\n",
    "    tick = yf.download(ticker, period=period)\n",
    "    tickerData = tick\n",
    "\n",
    "    returns = tickerData['Close'].pct_change() #calculates the daily returns of the stock as a percentage\n",
    "    daily_volatility = returns.std() #calculates the standard deviation of the stock returns to represent sigma in random walk eq.\n",
    "    \n",
    "    index = tickerData.index\n",
    "    length = len(index)\n",
    "    count = 0\n",
    "    predicted_prices = []\n",
    "    last_price = tickerData['Close'][0]\n",
    "\n",
    "    price = last_price #sets the initial price\n",
    "    predicted_prices.append(price) \n",
    "    \n",
    "    for y in range(length): #for loop runs for the length of time given\n",
    "        if count == length-1:\n",
    "            break\n",
    "        price = predicted_prices[count] * (1 + np.random.normal(0, daily_volatility)) #calculates prices with random walk equation\n",
    "        predicted_prices.append(price) #adds price to list\n",
    "        count += 1\n",
    "        \n",
    "    actualPrice = tickerData.Close \n",
    "    rmse = mean_squared_error(actualPrice, predicted_prices, squared = False)\n",
    "    print(\"MAPE: \", mean_absolute_percentage_error(actualPrice, predicted_prices))\n",
    "    print(\"RMSE: \", rmse)\n",
    "    \n",
    "    df = pd.DataFrame(predicted_prices)\n",
    "    df.index = tickerData.index\n",
    "    \n",
    "    ax = df.plot()\n",
    "    tickerData['Close'].plot(label=\"Close\", ax=ax,figsize=(15,7),grid=True)\n",
    "    \n",
    "    \n",
    "randomWalk('HL', '1y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823e19f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_objective, plot_histogram\n",
    "\n",
    "linear = BayesSearchCV(\n",
    "    SVR(),\n",
    "    {\n",
    "        'C': Real(0.1, 2.0, 'log-uniform'),\n",
    "        'kernel': ['linear'],  # categorical parameter\n",
    "    },\n",
    "    n_iter=200,\n",
    "    n_jobs=4,\n",
    "    n_points=2,\n",
    "    cv=2,\n",
    "    random_state = 1\n",
    ")\n",
    "\n",
    "rbf = BayesSearchCV(\n",
    "    SVR(),\n",
    "    {\n",
    "        'C': Real(0.1, 2.0, 'log-uniform'),\n",
    "        'gamma': Real(0.1, 10, 'log-uniform'),\n",
    "        'kernel': ['rbf'],  # categorical parameter\n",
    "    },\n",
    "    n_iter=200,\n",
    "    n_jobs=6,\n",
    "    n_points=3,\n",
    "    cv=2,\n",
    "    random_state = 1\n",
    ")\n",
    "poly = BayesSearchCV(\n",
    "    SVR(),\n",
    "    {\n",
    "        'C': Real(0.1, 2.0, 'log-uniform'),\n",
    "        'gamma': Real(0.1, 10, 'log-uniform'),\n",
    "        'degree': Integer(1, 5, 'log-uniform'),\n",
    "        'kernel': ['poly'],  # categorical parameter\n",
    "    },\n",
    "    n_iter=200,\n",
    "    n_jobs=8,\n",
    "    n_points=4,\n",
    "    cv=2,\n",
    "    random_state = 1\n",
    ")\n",
    "train_x, train_y, test_x, test_y = ticker_data_processing('F', '15y')\n",
    "t0 = time.time()\n",
    "model = poly.fit(train_x, train_y)\n",
    "print(poly.score(test_x, test_y))\n",
    "print(\"Parameters:\")\n",
    "print(poly.best_params_)\n",
    "t1 = time.time()\n",
    "total = t1-t0\n",
    "print(\"It took this long: %s\" % total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7814de69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
